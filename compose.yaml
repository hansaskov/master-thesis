services:
  ## The frontend service will build the frontend and then serve the files using caddy.
  frontend: 
    profiles: [stateless]
    build: 
      context: .
      dockerfile: ./services/frontend/dockerfile
    networks:
      - proxy_network
    labels:
      caddy: "${INTERFACE_FQDN}"
      caddy.encode: zstd gzip
      caddy.reverse_proxy: "{{upstreams 5173}}"

  ## The Backend will host our REST JSON api. Our spa will use this for data communication.
  backend: 
    profiles: [stateless]
    build: 
      context: .
      dockerfile: ./services/backend/dockerfile
    networks:
      - proxy_network
    environment:
      - DATABASE_URL=${DATABASE_URL}
      - GITHUB_CLIENT_ID=${GITHUB_CLIENT_ID}
      - GITHUB_CLIENT_SECRET=${GITHUB_CLIENT_SECRET}
      - MICROSOFT_TENANT_ID=${MICROSOFT_TENANT_ID}
      - MICROSOFT_CLIENT_ID=${MICROSOFT_CLIENT_ID}
      - MICROSOFT_CLIENT_SECRET=${MICROSOFT_CLIENT_SECRET}
      - MICROSOFT_REDIRECT_URI=${MICROSOFT_REDIRECT_URI}
      - PROD=${PROD}
    labels:
      caddy: "${INTERFACE_FQDN}"
      caddy.handle: /api/*
      caddy.handle.reverse_proxy: "{{upstreams 3000}}"

  ## A postgres database optimised for timeseries data
  timescaledb:
    profiles: [stateful]    
    image: timescale/timescaledb:latest-pg17
    restart: always
    environment:
      - POSTGRES_DB=${POSTGRES_DB}
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
    volumes:
      - timescaledb-data:/var/lib/postgresql/data
    
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER} -d ${POSTGRES_DB}"]
      interval: 10s
      retries: 5
      start_period: 30s
      timeout: 10s

volumes:
  timescaledb-data:

networks:
  proxy_network:
    external: true